# Site Crawler
This is a play around in learning Rust. It should crawl a single root url(?) findingall possible links and resources and follow them if they are of the same root url and then report on the different urls used in the website.

## Running
```
$ cargo run
```

## Useful Resources
```
- http://blog.skylight.io/rust-means-never-having-to-close-a-socket/
- https://docs.rs/hyper/0.11.1/hyper/  # Hyper documentation
- https://doc.rust-lang.org/std/  # Standard library documentation for Rust
- https://doc.rust-lang.org/book/second-edition  # Basic tutorial
```
